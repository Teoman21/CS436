{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2pqCT1ZkCwlJ"
      },
      "outputs": [],
      "source": [
        "# Importing the modules\n",
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z7JW_trgDXRG"
      },
      "outputs": [],
      "source": [
        "def synthetic_data(w, b, num_examples): #@save\n",
        "  \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
        "  X = torch.normal(0, 1, (num_examples, len(w)))\n",
        "  y = torch.matmul(X, w) + b #why didnt used np.dot()\n",
        "  y += torch.normal(0, 0.01, y.shape)\n",
        "  return X, y.reshape((-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2h4DqpnDEIP0"
      },
      "outputs": [],
      "source": [
        "# data preperation\n",
        "def data_iter(batch_size, features, labels):\n",
        "  num_examples = len(features)\n",
        "  indices = list(range(num_examples))\n",
        "  # The examples are read at random, in no particular order\n",
        "  random.shuffle(indices)\n",
        "  for i in range(0, num_examples, batch_size):\n",
        "    batch_indices = torch.tensor(indices[i:min(i +\n",
        "    batch_size, num_examples)])\n",
        "  yield features[batch_indices], labels[batch_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z-mKBtcvEhQv"
      },
      "outputs": [],
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True): #@save\n",
        "  \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "  dataset = data.TensorDataset(*data_arrays)\n",
        "  return data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HG-G_g6LE0y_"
      },
      "outputs": [],
      "source": [
        "## preparing the dataset\n",
        "n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5\n",
        "true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05\n",
        "train_data = synthetic_data(true_w, true_b, n_train)\n",
        "train_iter = load_array(train_data, batch_size)\n",
        "test_data = synthetic_data(true_w, true_b, n_test)\n",
        "test_iter = load_array(test_data, batch_size, is_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5fuNQrTOE3uh"
      },
      "outputs": [],
      "source": [
        "def init_params():\n",
        "  w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)\n",
        "  b = torch.zeros(1, requires_grad=True)\n",
        "  return [w, b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iKgir2xbH6J5"
      },
      "outputs": [],
      "source": [
        "def l2_penalty(w):\n",
        "  return torch.sum(w.pow(2)) / 2\n",
        "\n",
        "\n",
        "# defining the learning algorithm\n",
        "def sgd(params, lr, batch_size):\n",
        "  \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "  with torch.no_grad():\n",
        "    for param in params:\n",
        "      param -= lr * param.grad / batch_size\n",
        "      param.grad.zero_()\n",
        "\n",
        "# forward\n",
        "def linreg(X, theta_1, theta_0):\n",
        "  \"\"\"The linear regression model.\"\"\"\n",
        "  return torch.matmul(X, theta_1) + theta_0\n",
        "\n",
        "\n",
        "# Computing the MSE\n",
        "def MSE_loss(y_out, y_true):\n",
        "  \"\"\"Squared loss.\"\"\"\n",
        "  return (y_out - y_true.reshape(y_out.shape))**2 / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oq4aZg6aH8TZ"
      },
      "outputs": [],
      "source": [
        "def train(lambd):\n",
        "  w, b = init_params()\n",
        "  net, loss = lambda X: linreg(X, w, b), MSE_loss\n",
        "  num_epochs, lr = 100, 0.01\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    for X, y in train_iter:\n",
        "      # The L2 norm penalty term has been added, and broadcasting\n",
        "      # makes `l2_penalty(w)` a vector whose length is `batch_size`\n",
        "      l = loss(net(X), y) + lambd * l2_penalty(w)\n",
        "      l.sum().backward()\n",
        "      sgd([w, b], lr, batch_size)\n",
        "      print(\"Loss\", l.sum())\n",
        "      print('L2 norm of w:', torch.norm(w).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8UMMHzWIIV7",
        "outputId": "2f47fc9a-06c3-4b15-cd49-fc3c8dfa41a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss tensor(423.4085, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.637124061584473\n",
            "Loss tensor(720.3859, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.48731803894043\n",
            "Loss tensor(951.5809, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.294082641601562\n",
            "Loss tensor(93.4011, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.274580955505371\n",
            "Loss tensor(248.9888, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.221720695495605\n",
            "Loss tensor(131.9106, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.193304061889648\n",
            "Loss tensor(119.6603, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.16749095916748\n",
            "Loss tensor(86.2134, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.14908504486084\n",
            "Loss tensor(48.2394, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.13801097869873\n",
            "Loss tensor(81.6414, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.120823860168457\n",
            "Loss tensor(19.3650, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.116085052490234\n",
            "Loss tensor(37.6804, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.108207702636719\n",
            "Loss tensor(27.1181, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.10265064239502\n",
            "Loss tensor(8.4952, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.100675582885742\n",
            "Loss tensor(21.0968, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.095514297485352\n",
            "Loss tensor(11.1847, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.09306526184082\n",
            "Loss tensor(3.6397, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.092243194580078\n",
            "Loss tensor(3.6269, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.09148120880127\n",
            "Loss tensor(14.7841, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08786678314209\n",
            "Loss tensor(3.1222, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08703327178955\n",
            "Loss tensor(1.2179, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.086762428283691\n",
            "Loss tensor(1.8022, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.086358070373535\n",
            "Loss tensor(2.7523, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08548641204834\n",
            "Loss tensor(4.5401, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.084321022033691\n",
            "Loss tensor(1.1285, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.084071159362793\n",
            "Loss tensor(1.0579, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.083742141723633\n",
            "Loss tensor(2.0716, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.083088874816895\n",
            "Loss tensor(0.6084, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08292007446289\n",
            "Loss tensor(0.3735, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08279037475586\n",
            "Loss tensor(0.4984, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.082620620727539\n",
            "Loss tensor(1.0129, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.082344055175781\n",
            "Loss tensor(0.5797, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.082148551940918\n",
            "Loss tensor(0.2585, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.082048416137695\n",
            "Loss tensor(0.1058, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.082061767578125\n",
            "Loss tensor(0.7144, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081812858581543\n",
            "Loss tensor(0.2066, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081690788269043\n",
            "Loss tensor(0.3445, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081537246704102\n",
            "Loss tensor(0.1037, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081501960754395\n",
            "Loss tensor(0.1985, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081417083740234\n",
            "Loss tensor(0.0625, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081415176391602\n",
            "Loss tensor(0.0468, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081396102905273\n",
            "Loss tensor(0.2004, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081286430358887\n",
            "Loss tensor(0.0610, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081263542175293\n",
            "Loss tensor(0.0808, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081233024597168\n",
            "Loss tensor(0.1202, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08117389678955\n",
            "Loss tensor(0.0554, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081140518188477\n",
            "Loss tensor(0.0427, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081120491027832\n",
            "Loss tensor(0.0094, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081111907958984\n",
            "Loss tensor(0.0103, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081095695495605\n",
            "Loss tensor(0.0224, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081075668334961\n",
            "Loss tensor(0.0294, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081048011779785\n",
            "Loss tensor(0.0696, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08102798461914\n",
            "Loss tensor(0.0042, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081029891967773\n",
            "Loss tensor(0.0168, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.081019401550293\n",
            "Loss tensor(0.0329, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08099365234375\n",
            "Loss tensor(0.0251, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080965995788574\n",
            "Loss tensor(0.0184, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080954551696777\n",
            "Loss tensor(0.0137, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080937385559082\n",
            "Loss tensor(0.0044, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080941200256348\n",
            "Loss tensor(0.0088, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080924987792969\n",
            "Loss tensor(0.0030, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080920219421387\n",
            "Loss tensor(0.0069, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080912590026855\n",
            "Loss tensor(0.0134, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080894470214844\n",
            "Loss tensor(0.0026, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08089828491211\n",
            "Loss tensor(0.0024, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080889701843262\n",
            "Loss tensor(0.0011, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080889701843262\n",
            "Loss tensor(0.0024, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080887794494629\n",
            "Loss tensor(0.0094, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080877304077148\n",
            "Loss tensor(0.0005, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080877304077148\n",
            "Loss tensor(0.0008, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080876350402832\n",
            "Loss tensor(0.0039, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080872535705566\n",
            "Loss tensor(0.0042, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08086109161377\n",
            "Loss tensor(0.0009, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08085823059082\n",
            "Loss tensor(0.0006, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080857276916504\n",
            "Loss tensor(0.0015, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080856323242188\n",
            "Loss tensor(0.0026, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080850601196289\n",
            "Loss tensor(0.0012, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08084774017334\n",
            "Loss tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080842971801758\n",
            "Loss tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080842018127441\n",
            "Loss tensor(0.0006, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080842018127441\n",
            "Loss tensor(0.0003, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080841064453125\n",
            "Loss tensor(0.0010, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080839157104492\n",
            "Loss tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080836296081543\n",
            "Loss tensor(0.0003, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08083438873291\n",
            "Loss tensor(0.0005, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080831527709961\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080830574035645\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080830574035645\n",
            "Loss tensor(0.0003, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080828666687012\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080827713012695\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080827713012695\n",
            "Loss tensor(8.5634e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080827713012695\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080825805664062\n",
            "Loss tensor(4.6756e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080825805664062\n",
            "Loss tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080822944641113\n",
            "Loss tensor(9.8036e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08082389831543\n",
            "Loss tensor(2.7470e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08082389831543\n",
            "Loss tensor(5.2588e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080822944641113\n",
            "Loss tensor(5.5679e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080821990966797\n",
            "Loss tensor(4.3283e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08082103729248\n",
            "Loss tensor(9.9700e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08082103729248\n",
            "Loss tensor(7.6132e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080820083618164\n",
            "Loss tensor(3.4002e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080819129943848\n",
            "Loss tensor(1.8560e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080819129943848\n",
            "Loss tensor(1.3696e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080820083618164\n",
            "Loss tensor(3.4199e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080819129943848\n",
            "Loss tensor(7.2673e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080819129943848\n",
            "Loss tensor(2.6719e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080819129943848\n",
            "Loss tensor(1.9046e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(1.6940e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(4.8326e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(1.6849e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(1.3890e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(6.3316e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080816268920898\n",
            "Loss tensor(4.4719e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080817222595215\n",
            "Loss tensor(1.2307e-05, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080816268920898\n",
            "Loss tensor(8.4415e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080816268920898\n",
            "Loss tensor(5.3107e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080816268920898\n",
            "Loss tensor(8.6598e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080816268920898\n",
            "Loss tensor(1.9938e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(2.5834e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(6.3887e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(2.1044e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(3.7961e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(4.5908e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(9.2889e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(3.7012e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(3.4642e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(1.6594e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(8.6890e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(1.5874e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080815315246582\n",
            "Loss tensor(1.1366e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(5.1159e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(2.2275e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(5.1938e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(5.4442e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(1.1145e-06, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(4.0895e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3323e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(1.5869e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(6.9480e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(2.1603e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(5.5736e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9234e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(1.7648e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2876e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(2.7619e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(4.9346e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.0689e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.9309e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.3647e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(6.7968e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3468e-07, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(3.3349e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.4018e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.5954e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.1806e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.8672e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(2.0635e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(2.2549e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.9294e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.6571e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(8.8863e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.2526e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2374e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2898e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.9183e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080814361572266\n",
            "Loss tensor(1.3144e-08, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(7.6881e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.1400e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(5.8217e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.5235e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6369e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2799e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.2066e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(2.8454e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3466e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.8418e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.6474e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(2.0863e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.5721e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2280e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4032e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.7928e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.5702e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.4483e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(6.8598e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(1.2977e-09, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.1754e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.6165e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(5.3965e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.6770e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.1470e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.080812454223633\n",
            "Loss tensor(3.9379e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.1878e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.0254e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.1208e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.1189e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.7863e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2822e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5102e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.3190e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1407e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.2657e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.1348e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9516e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.3834e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0512e-10, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.4784e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9009e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.8847e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.2251e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.2714e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.8849e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.7584e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9106e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9590e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.7122e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9985e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.1905e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.7020e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.7539e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1864e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3519e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.1010e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.0131e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6718e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.0720e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.7667e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6607e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9327e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7880e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.6093e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0218e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.7523e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.6061e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.9468e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7828e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4677e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2414e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.8011e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.5108e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2536e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7067e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.5082e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.4334e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6168e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3092e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3765e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.8360e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1565e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.2739e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5740e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.1924e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7166e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.0336e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.5321e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.2660e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.3607e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.7028e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1973e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.6216e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.1563e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0450e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2222e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4766e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.5567e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.1462e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3877e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.1683e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6589e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.5593e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.0369e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.3267e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.4428e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2955e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0019e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5741e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.2382e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.3881e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.3863e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.8826e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.2891e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3877e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.9830e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2366e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0908e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.6346e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.2237e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.0101e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6735e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1251e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.1671e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.2066e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2327e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.4868e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3363e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.9671e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3082e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.8836e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.1472e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3514e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1178e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.8099e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.1938e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9972e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0914e-11, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.2554e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.2177e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.6611e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.4398e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.5541e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.1078e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.0064e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1352e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.9781e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.5534e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7233e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.0592e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.8769e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.2872e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.9496e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.8330e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.6906e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.4749e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.2341e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.2254e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.5242e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.6739e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(8.6710e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.9223e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9921e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.4877e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.2148e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.7328e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2350e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3937e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.9321e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1103e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.1500e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3289e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.9484e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.8618e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.2576e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.1387e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.8213e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.3410e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.5367e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1157e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.6297e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0224e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.9007e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.7395e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6157e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.0040e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(5.2128e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5509e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5925e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.6212e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.5391e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.8092e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(6.6983e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3455e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3989e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.8338e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.2182e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.9458e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.9714e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.2044e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0312e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.4497e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.7709e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6210e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6106e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.9509e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.8003e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9718e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.1493e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.5235e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.7206e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4973e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.0923e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(4.3541e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.6064e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4392e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.5649e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(7.6383e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.9669e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5732e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.1489e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.7811e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(3.3995e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3845e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.1917e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.4032e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(2.3652e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.3444e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.5933e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.1623e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(1.8183e-12, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n",
            "Loss tensor(9.4879e-13, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 15.08081340789795\n"
          ]
        }
      ],
      "source": [
        "train(lambd=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoNtIyQaIfcG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_m1J6pcnKeSj"
      },
      "outputs": [],
      "source": [
        "def train(lambd):\n",
        "  w, b = init_params()\n",
        "  net, loss = lambda X: linreg(X, w, b), MSE_loss\n",
        "  num_epochs, lr = 100, 0.01\n",
        "  for epoch in range(num_epochs):\n",
        "    #adapting Learning rate\n",
        "    lr  = lr * (1000/(1000+epoch))\n",
        "    print(lr)\n",
        "    for X, y in train_iter:\n",
        "      # The L2 norm penalty term has been added, and broadcasting\n",
        "      # makes `l2_penalty(w)` a vector whose length is `batch_size`\n",
        "      l = loss(net(X), y) + lambd * l2_penalty(w)\n",
        "      l.sum().backward()\n",
        "\n",
        "      sgd([w, b], lr, batch_size)\n",
        "      print(\"Loss\", l.sum())\n",
        "      print('L2 norm of w:', torch.norm(w).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOs3aIp_PCs1",
        "outputId": "8315f1b6-4dfb-4ffe-a255-eae6d17e57e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.01\n",
            "Loss tensor(1781.7705, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 13.727041244506836\n",
            "Loss tensor(2139.0605, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 13.146439552307129\n",
            "Loss tensor(1794.7024, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 12.634703636169434\n",
            "Loss tensor(1482.0585, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 12.184324264526367\n",
            "0.00999000999000999\n",
            "Loss tensor(1252.6794, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 11.782763481140137\n",
            "Loss tensor(1091.4893, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 11.416189193725586\n",
            "Loss tensor(1114.7555, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 11.035908699035645\n",
            "Loss tensor(1006.6398, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 10.677200317382812\n",
            "0.009970069850309371\n",
            "Loss tensor(891.8154, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 10.346963882446289\n",
            "Loss tensor(837.6575, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 10.026973724365234\n",
            "Loss tensor(776.9424, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 9.719977378845215\n",
            "Loss tensor(738.3115, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 9.419658660888672\n",
            "0.00994024910300037\n",
            "Loss tensor(677.6091, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 9.134488105773926\n",
            "Loss tensor(637.9207, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 8.85765552520752\n",
            "Loss tensor(600.6005, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 8.589218139648438\n",
            "Loss tensor(554.3025, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 8.332767486572266\n",
            "0.00990064651693264\n",
            "Loss tensor(525.2200, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 8.083612442016602\n",
            "Loss tensor(494.4708, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 7.841668128967285\n",
            "Loss tensor(461.6659, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 7.608570575714111\n",
            "Loss tensor(437.4477, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 7.3811821937561035\n",
            "0.009851389569087205\n",
            "Loss tensor(409.9391, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 7.162461757659912\n",
            "Loss tensor(385.5240, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 6.950416088104248\n",
            "Loss tensor(363.5844, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 6.744333267211914\n",
            "Loss tensor(342.1054, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 6.544587135314941\n",
            "0.009792633766488276\n",
            "Loss tensor(321.6688, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 6.352113723754883\n",
            "Loss tensor(303.0612, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 6.165273666381836\n",
            "Loss tensor(285.4385, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.983931541442871\n",
            "Loss tensor(268.9427, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.807941436767578\n",
            "0.009724561833652707\n",
            "Loss tensor(253.1906, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.638397216796875\n",
            "Loss tensor(238.6336, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.473796844482422\n",
            "Loss tensor(224.8605, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.314036846160889\n",
            "Loss tensor(211.9048, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.158909320831299\n",
            "0.009647382771480861\n",
            "Loss tensor(199.6938, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 5.009536266326904\n",
            "Loss tensor(188.2463, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.864525318145752\n",
            "Loss tensor(177.5547, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.7236833572387695\n",
            "Loss tensor(167.4295, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.586949825286865\n",
            "0.009561330794331874\n",
            "Loss tensor(157.8203, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.455382823944092\n",
            "Loss tensor(148.9116, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.327554702758789\n",
            "Loss tensor(140.4707, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.203408718109131\n",
            "Loss tensor(132.5622, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 4.082810401916504\n",
            "0.009466664152803835\n",
            "Loss tensor(125.0324, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.966853141784668\n",
            "Loss tensor(118.0303, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.854199171066284\n",
            "Loss tensor(111.4245, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.744743824005127\n",
            "Loss tensor(105.1929, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.6383776664733887\n",
            "0.009363663850448898\n",
            "Loss tensor(99.2912, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.5361785888671875\n",
            "Loss tensor(93.7875, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.436849594116211\n",
            "Loss tensor(88.5966, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.3402976989746094\n",
            "Loss tensor(83.6928, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.2464730739593506\n",
            "0.009252632263289425\n",
            "Loss tensor(79.0492, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.156367301940918\n",
            "Loss tensor(74.7267, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 3.0687596797943115\n",
            "Loss tensor(70.6320, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.983585834503174\n",
            "Loss tensor(66.7703, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.900770425796509\n",
            "0.009133891671559157\n",
            "Loss tensor(63.1093, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.8212833404541016\n",
            "Loss tensor(59.7017, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.7439873218536377\n",
            "Loss tensor(56.4793, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.6688232421875\n",
            "Loss tensor(53.4222, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.5956966876983643\n",
            "0.009007782713569189\n",
            "Loss tensor(50.5348, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.5255630016326904\n",
            "Loss tensor(47.8428, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.457333564758301\n",
            "Loss tensor(45.2899, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.3909318447113037\n",
            "Loss tensor(42.8783, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.326331853866577\n",
            "0.00887466277198935\n",
            "Loss tensor(40.5924, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.264416217803955\n",
            "Loss tensor(38.4587, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.2041330337524414\n",
            "Loss tensor(36.4408, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.1454713344573975\n",
            "Loss tensor(34.5238, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.0883541107177734\n",
            "0.008734904303139123\n",
            "Loss tensor(32.7115, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 2.0336413383483887\n",
            "Loss tensor(31.0207, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.9803659915924072\n",
            "Loss tensor(29.4169, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.9284875392913818\n",
            "Loss tensor(27.8963, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.8779672384262085\n",
            "0.008588893120097465\n",
            "Loss tensor(26.4525, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.8295891284942627\n",
            "Loss tensor(25.1096, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.7824690341949463\n",
            "Loss tensor(23.8326, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.7365604639053345\n",
            "Loss tensor(22.6189, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.6918270587921143\n",
            "0.008437026640567254\n",
            "Loss tensor(21.4693, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.6490223407745361\n",
            "Loss tensor(20.3964, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.6072930097579956\n",
            "Loss tensor(19.3812, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.5666447877883911\n",
            "Loss tensor(18.4091, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.5270013809204102\n",
            "0.008279712110468355\n",
            "Loss tensor(17.4887, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.4890773296356201\n",
            "Loss tensor(16.6351, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.4521257877349854\n",
            "Loss tensor(15.8190, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.4160839319229126\n",
            "Loss tensor(15.0406, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.380916714668274\n",
            "0.00811736481418466\n",
            "Loss tensor(14.3030, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.347299337387085\n",
            "Loss tensor(13.6159, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.314504861831665\n",
            "Loss tensor(12.9665, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.2825461626052856\n",
            "Loss tensor(12.3377, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.2513175010681152\n",
            "0.007950406282257258\n",
            "Loss tensor(11.7454, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.2214915752410889\n",
            "Loss tensor(11.1931, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.1923801898956299\n",
            "Loss tensor(10.6681, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.1639785766601562\n",
            "Loss tensor(10.1620, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.1362231969833374\n",
            "0.007779262507101034\n",
            "Loss tensor(9.6843, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.109724521636963\n",
            "Loss tensor(9.2388, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.0838508605957031\n",
            "Loss tensor(8.8142, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.0585891008377075\n",
            "Loss tensor(8.4071, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.0339033603668213\n",
            "0.007604362177029359\n",
            "Loss tensor(8.0202, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 1.0103527307510376\n",
            "Loss tensor(7.6586, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.9873259663581848\n",
            "Loss tensor(7.3132, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.9648188948631287\n",
            "Loss tensor(6.9841, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.9428335428237915\n",
            "0.007426134938505234\n",
            "Loss tensor(6.6713, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.9218762516975403\n",
            "Loss tensor(6.3747, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.9013504385948181\n",
            "Loss tensor(6.0961, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.8812962770462036\n",
            "Loss tensor(5.8271, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.8616824746131897\n",
            "0.007245009696102667\n",
            "Loss tensor(5.5712, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.8429876565933228\n",
            "Loss tensor(5.3319, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.8246893286705017\n",
            "Loss tensor(5.1040, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.8067941069602966\n",
            "Loss tensor(4.8846, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7892864942550659\n",
            "0.007061412959164392\n",
            "Loss tensor(4.6746, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7725968360900879\n",
            "Loss tensor(4.4779, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7562422752380371\n",
            "Loss tensor(4.2896, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7402254939079285\n",
            "Loss tensor(4.1169, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7246243953704834\n",
            "0.006875767243587529\n",
            "Loss tensor(3.9393, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.7096932530403137\n",
            "Loss tensor(3.7803, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6950942873954773\n",
            "Loss tensor(3.6265, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6807851195335388\n",
            "Loss tensor(3.4797, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6667890548706055\n",
            "0.0066884895365637445\n",
            "Loss tensor(3.3357, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6534281969070435\n",
            "Loss tensor(3.2042, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6403381824493408\n",
            "Loss tensor(3.0798, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6275513768196106\n",
            "Loss tensor(2.9567, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6149970889091492\n",
            "0.006499989831451647\n",
            "Loss tensor(2.8381, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.6030316352844238\n",
            "Loss tensor(2.7296, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5913037061691284\n",
            "Loss tensor(2.6270, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5798318982124329\n",
            "Loss tensor(2.5231, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5685495138168335\n",
            "0.006310669739273444\n",
            "Loss tensor(2.4262, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.557818591594696\n",
            "Loss tensor(2.3356, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5472843647003174\n",
            "Loss tensor(2.2481, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.536946713924408\n",
            "Loss tensor(2.1673, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5268495678901672\n",
            "0.006120921182612458\n",
            "Loss tensor(2.0822, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5171815752983093\n",
            "Loss tensor(2.0104, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.5077594518661499\n",
            "Loss tensor(1.9363, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.49848008155822754\n",
            "Loss tensor(1.8662, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.48935678601264954\n",
            "0.005931125176950056\n",
            "Loss tensor(1.7978, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4806821942329407\n",
            "Loss tensor(1.7364, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.47218671441078186\n",
            "Loss tensor(1.6743, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.46381720900535583\n",
            "Loss tensor(1.6157, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.45560163259506226\n",
            "0.005741650703727063\n",
            "Loss tensor(1.5599, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4478110074996948\n",
            "Loss tensor(1.5065, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.44014638662338257\n",
            "Loss tensor(1.4560, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4326117932796478\n",
            "Loss tensor(1.4045, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4251699447631836\n",
            "0.005552853678652866\n",
            "Loss tensor(1.3588, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4181416630744934\n",
            "Loss tensor(1.3139, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.41122639179229736\n",
            "Loss tensor(1.2698, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.4043996334075928\n",
            "Loss tensor(1.2292, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3977062702178955\n",
            "0.005365076018022092\n",
            "Loss tensor(1.1896, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.39137181639671326\n",
            "Loss tensor(1.1516, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.38512974977493286\n",
            "Loss tensor(1.1141, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.37895816564559937\n",
            "Loss tensor(1.0788, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.37288111448287964\n",
            "0.005178644805040629\n",
            "Loss tensor(1.0458, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3671507239341736\n",
            "Loss tensor(1.0142, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3615090847015381\n",
            "Loss tensor(0.9830, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.35593968629837036\n",
            "Loss tensor(0.9509, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3504171669483185\n",
            "0.004993871557416228\n",
            "Loss tensor(0.9231, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3452093005180359\n",
            "Loss tensor(0.8967, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3401011526584625\n",
            "Loss tensor(0.8687, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3350250720977783\n",
            "Loss tensor(0.8457, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3300703167915344\n",
            "0.004811051596740105\n",
            "Loss tensor(0.8197, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.32536712288856506\n",
            "Loss tensor(0.7963, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.32071778178215027\n",
            "Loss tensor(0.7727, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3161042332649231\n",
            "Loss tensor(0.7533, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3116101324558258\n",
            "0.004630463519480371\n",
            "Loss tensor(0.7307, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3073330819606781\n",
            "Loss tensor(0.7115, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.3031262457370758\n",
            "Loss tensor(0.6916, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2989586591720581\n",
            "Loss tensor(0.6723, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.29484349489212036\n",
            "0.004452368768731126\n",
            "Loss tensor(0.6539, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.29095008969306946\n",
            "Loss tensor(0.6369, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2871040999889374\n",
            "Loss tensor(0.6197, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2832942306995392\n",
            "Loss tensor(0.6066, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2796008288860321\n",
            "0.004277011305217219\n",
            "Loss tensor(0.5881, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.27605438232421875\n",
            "Loss tensor(0.5740, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.27255865931510925\n",
            "Loss tensor(0.5611, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2691354751586914\n",
            "Loss tensor(0.5449, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2657194137573242\n",
            "0.004104617375448387\n",
            "Loss tensor(0.5326, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2625119090080261\n",
            "Loss tensor(0.5188, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.25932011008262634\n",
            "Loss tensor(0.5065, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.25616857409477234\n",
            "Loss tensor(0.4946, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2530654966831207\n",
            "0.003935395374351282\n",
            "Loss tensor(0.4811, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2500949800014496\n",
            "Loss tensor(0.4694, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2471504509449005\n",
            "Loss tensor(0.4630, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.24433301389217377\n",
            "Loss tensor(0.4521, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.24152947962284088\n",
            "0.0037695357991870517\n",
            "Loss tensor(0.4402, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2388606071472168\n",
            "Loss tensor(0.4313, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.23623347282409668\n",
            "Loss tensor(0.4194, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.23358014225959778\n",
            "Loss tensor(0.4118, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.23098240792751312\n",
            "0.0036072112910880876\n",
            "Loss tensor(0.4026, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.22853131592273712\n",
            "Loss tensor(0.3922, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.22607022523880005\n",
            "Loss tensor(0.3869, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.22370143234729767\n",
            "Loss tensor(0.3786, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2213452011346817\n",
            "0.0034485767601224546\n",
            "Loss tensor(0.3714, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.21914085745811462\n",
            "Loss tensor(0.3619, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.216901957988739\n",
            "Loss tensor(0.3540, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.21468760073184967\n",
            "Loss tensor(0.3482, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2125198394060135\n",
            "0.0032937695894197276\n",
            "Loss tensor(0.3409, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2104627937078476\n",
            "Loss tensor(0.3337, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.20842255651950836\n",
            "Loss tensor(0.3293, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2064242660999298\n",
            "Loss tensor(0.3221, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.20443883538246155\n",
            "0.0031429099135684424\n",
            "Loss tensor(0.3172, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.20258475840091705\n",
            "Loss tensor(0.3107, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.2007431536912918\n",
            "Loss tensor(0.3039, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19888581335544586\n",
            "Loss tensor(0.2976, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19702443480491638\n",
            "0.002996100966223491\n",
            "Loss tensor(0.2938, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19530239701271057\n",
            "Loss tensor(0.2877, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19358086585998535\n",
            "Loss tensor(0.2841, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19189874827861786\n",
            "Loss tensor(0.2785, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.19022740423679352\n",
            "0.00285342949164142\n",
            "Loss tensor(0.2721, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.18861442804336548\n",
            "Loss tensor(0.2706, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1870865523815155\n",
            "Loss tensor(0.2651, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1855248510837555\n",
            "Loss tensor(0.2607, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1839849203824997\n",
            "0.002714966214692122\n",
            "Loss tensor(0.2565, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1825370490550995\n",
            "Loss tensor(0.2525, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.18110749125480652\n",
            "Loss tensor(0.2465, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.17964264750480652\n",
            "Loss tensor(0.2459, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.17824746668338776\n",
            "0.002580766363775781\n",
            "Loss tensor(0.2414, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.17693071067333221\n",
            "Loss tensor(0.2365, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1755976378917694\n",
            "Loss tensor(0.2349, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1743033081293106\n",
            "Loss tensor(0.2287, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.17296913266181946\n",
            "0.002450870241002641\n",
            "Loss tensor(0.2261, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1717306673526764\n",
            "Loss tensor(0.2238, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.17051519453525543\n",
            "Loss tensor(0.2214, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1693243533372879\n",
            "Loss tensor(0.2170, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16811493039131165\n",
            "0.00232530383396835\n",
            "Loss tensor(0.2142, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1669800728559494\n",
            "Loss tensor(0.2097, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16582319140434265\n",
            "Loss tensor(0.2091, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16472004354000092\n",
            "Loss tensor(0.2075, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16364723443984985\n",
            "0.002204079463477109\n",
            "Loss tensor(0.2016, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16257724165916443\n",
            "Loss tensor(0.1992, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.16151751577854156\n",
            "Loss tensor(0.1989, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1605137586593628\n",
            "Loss tensor(0.1980, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15953250229358673\n",
            "0.0020871964616260502\n",
            "Loss tensor(0.1939, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15859349071979523\n",
            "Loss tensor(0.1921, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15765927731990814\n",
            "Loss tensor(0.1872, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15668226778507233\n",
            "Loss tensor(0.1861, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15573352575302124\n",
            "0.0019746418747644753\n",
            "Loss tensor(0.1839, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15483731031417847\n",
            "Loss tensor(0.1831, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15397854149341583\n",
            "Loss tensor(0.1805, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15311677753925323\n",
            "Loss tensor(0.1772, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15223252773284912\n",
            "0.001866391185977765\n",
            "Loss tensor(0.1748, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15139704942703247\n",
            "Loss tensor(0.1729, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.15056219696998596\n",
            "Loss tensor(0.1733, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14977668225765228\n",
            "Loss tensor(0.1726, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14900515973567963\n",
            "0.0017624090519147923\n",
            "Loss tensor(0.1677, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14823439717292786\n",
            "Loss tensor(0.1671, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1474839299917221\n",
            "Loss tensor(0.1668, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14676623046398163\n",
            "Loss tensor(0.1639, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14602522552013397\n",
            "0.0016626500489762192\n",
            "Loss tensor(0.1636, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1453513503074646\n",
            "Loss tensor(0.1613, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1446695178747177\n",
            "Loss tensor(0.1574, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14395572245121002\n",
            "Loss tensor(0.1577, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1432722806930542\n",
            "0.0015670594241057674\n",
            "Loss tensor(0.1546, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14260834455490112\n",
            "Loss tensor(0.1550, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14197315275669098\n",
            "Loss tensor(0.1541, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14135153591632843\n",
            "Loss tensor(0.1532, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1407325118780136\n",
            "0.0014755738456739805\n",
            "Loss tensor(0.1513, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.14015479385852814\n",
            "Loss tensor(0.1498, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13956505060195923\n",
            "Loss tensor(0.1482, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1389724165201187\n",
            "Loss tensor(0.1469, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1383850872516632\n",
            "0.001388122150210706\n",
            "Loss tensor(0.1453, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13783232867717743\n",
            "Loss tensor(0.1450, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13729418814182281\n",
            "Loss tensor(0.1418, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.136723130941391\n",
            "Loss tensor(0.1451, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13621786236763\n",
            "0.0013046260810250995\n",
            "Loss tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13570410013198853\n",
            "Loss tensor(0.1416, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13521645963191986\n",
            "Loss tensor(0.1381, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13470448553562164\n",
            "Loss tensor(0.1392, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1342153400182724\n",
            "0.0012250010150470418\n",
            "Loss tensor(0.1385, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13376644253730774\n",
            "Loss tensor(0.1361, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13329802453517914\n",
            "Loss tensor(0.1348, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13282588124275208\n",
            "Loss tensor(0.1347, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1323641985654831\n",
            "0.001149156674528182\n",
            "Loss tensor(0.1330, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13192664086818695\n",
            "Loss tensor(0.1323, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13149529695510864\n",
            "Loss tensor(0.1318, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13106009364128113\n",
            "Loss tensor(0.1327, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13065500557422638\n",
            "0.0010769978205512484\n",
            "Loss tensor(0.1303, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.13025999069213867\n",
            "Loss tensor(0.1297, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12986057996749878\n",
            "Loss tensor(0.1291, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1294722557067871\n",
            "Loss tensor(0.1277, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12907525897026062\n",
            "0.001008424925609783\n",
            "Loss tensor(0.1263, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12869836390018463\n",
            "Loss tensor(0.1280, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12835420668125153\n",
            "Loss tensor(0.1249, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12797893583774567\n",
            "Loss tensor(0.1256, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12761564552783966\n",
            "0.0009433348228342216\n",
            "Loss tensor(0.1254, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1272880882024765\n",
            "Loss tensor(0.1218, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12693017721176147\n",
            "Loss tensor(0.1244, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12660877406597137\n",
            "Loss tensor(0.1224, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1262671798467636\n",
            "0.000881621329751609\n",
            "Loss tensor(0.1221, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1259584277868271\n",
            "Loss tensor(0.1213, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12564438581466675\n",
            "Loss tensor(0.1202, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12533122301101685\n",
            "Loss tensor(0.1204, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12502171099185944\n",
            "0.0008231758447727442\n",
            "Loss tensor(0.1189, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12472512573003769\n",
            "Loss tensor(0.1191, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12443945556879044\n",
            "Loss tensor(0.1207, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12417413294315338\n",
            "Loss tensor(0.1162, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12387152016162872\n",
            "0.0007678879148999479\n",
            "Loss tensor(0.1173, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12360641360282898\n",
            "Loss tensor(0.1155, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12332843989133835\n",
            "Loss tensor(0.1190, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1230841651558876\n",
            "Loss tensor(0.1149, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12280941009521484\n",
            "0.0007156457734389076\n",
            "Loss tensor(0.1165, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12257116287946701\n",
            "Loss tensor(0.1155, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12232861667871475\n",
            "Loss tensor(0.1129, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.122073233127594\n",
            "Loss tensor(0.1141, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12182891368865967\n",
            "0.0006663368467773814\n",
            "Loss tensor(0.1133, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12160219252109528\n",
            "Loss tensor(0.1113, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12135980278253555\n",
            "Loss tensor(0.1127, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12113343924283981\n",
            "Loss tensor(0.1147, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12092448770999908\n",
            "0.0006198482295603548\n",
            "Loss tensor(0.1121, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12071722000837326\n",
            "Loss tensor(0.1120, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12051217257976532\n",
            "Loss tensor(0.1110, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12030212581157684\n",
            "Loss tensor(0.1106, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.12008967995643616\n",
            "0.0005760671278441958\n",
            "Loss tensor(0.1116, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11990427225828171\n",
            "Loss tensor(0.1092, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.119704969227314\n",
            "Loss tensor(0.1114, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11952222138643265\n",
            "Loss tensor(0.1076, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11931975185871124\n",
            "0.0005348812700503212\n",
            "Loss tensor(0.1093, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11914293467998505\n",
            "Loss tensor(0.1102, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1189751848578453\n",
            "Loss tensor(0.1067, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11878824979066849\n",
            "Loss tensor(0.1082, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11861005425453186\n",
            "0.0004961792857609658\n",
            "Loss tensor(0.1084, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11845013499259949\n",
            "Loss tensor(0.1086, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11829213052988052\n",
            "Loss tensor(0.1057, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11812049895524979\n",
            "Loss tensor(0.1068, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11795609444379807\n",
            "0.0004598510526051583\n",
            "Loss tensor(0.1063, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1178036630153656\n",
            "Loss tensor(0.1059, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11764935404062271\n",
            "Loss tensor(0.1048, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11749248206615448\n",
            "Loss tensor(0.1080, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11735398322343826\n",
            "0.00042578801167144286\n",
            "Loss tensor(0.1059, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11721611768007278\n",
            "Loss tensor(0.1063, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11708121001720428\n",
            "Loss tensor(0.1055, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1169457882642746\n",
            "Loss tensor(0.1032, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11679943650960922\n",
            "0.00039388345205498875\n",
            "Loss tensor(0.1046, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11667019128799438\n",
            "Loss tensor(0.1042, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1165410652756691\n",
            "Loss tensor(0.1054, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11641959846019745\n",
            "Loss tensor(0.1030, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11628925055265427\n",
            "0.0003640327653003593\n",
            "Loss tensor(0.1033, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11617016792297363\n",
            "Loss tensor(0.1024, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11604853719472885\n",
            "Loss tensor(0.1036, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11593027412891388\n",
            "Loss tensor(0.1044, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11582008749246597\n",
            "0.00033613367063745086\n",
            "Loss tensor(0.1023, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11570882052183151\n",
            "Loss tensor(0.1028, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11560139060020447\n",
            "Loss tensor(0.1026, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11549412459135056\n",
            "Loss tensor(0.1029, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11538884043693542\n",
            "0.00031008641202716873\n",
            "Loss tensor(0.1021, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11528897285461426\n",
            "Loss tensor(0.1017, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11518964171409607\n",
            "Loss tensor(0.1016, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11508988589048386\n",
            "Loss tensor(0.1022, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11499263346195221\n",
            "0.00028579392813563937\n",
            "Loss tensor(0.1013, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11490128189325333\n",
            "Loss tensor(0.1012, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11480995267629623\n",
            "Loss tensor(0.1027, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11472465097904205\n",
            "Loss tensor(0.0997, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11462884396314621\n",
            "0.00026316199644165687\n",
            "Loss tensor(0.1015, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11454624682664871\n",
            "Loss tensor(0.0999, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11446025967597961\n",
            "Loss tensor(0.0992, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11437316238880157\n",
            "Loss tensor(0.1019, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.114295095205307\n",
            "0.00024209935275221423\n",
            "Loss tensor(0.1005, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11421992629766464\n",
            "Loss tensor(0.1001, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11414291709661484\n",
            "Loss tensor(0.0993, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11406368017196655\n",
            "Loss tensor(0.1004, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11398904025554657\n",
            "0.00022251778745607925\n",
            "Loss tensor(0.0995, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11391834169626236\n",
            "Loss tensor(0.0999, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1138496920466423\n",
            "Loss tensor(0.1011, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11378317326307297\n",
            "Loss tensor(0.0978, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11370857059955597\n",
            "0.00020433221988620684\n",
            "Loss tensor(0.0977, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11364077031612396\n",
            "Loss tensor(0.0988, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1135757565498352\n",
            "Loss tensor(0.1020, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11351848393678665\n",
            "Loss tensor(0.0979, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1134517639875412\n",
            "0.0001874607521891806\n",
            "Loss tensor(0.1004, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11339564621448517\n",
            "Loss tensor(0.0968, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11333225667476654\n",
            "Loss tensor(0.0978, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11327236890792847\n",
            "Loss tensor(0.0997, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11321675777435303\n",
            "0.0001718247041147393\n",
            "Loss tensor(0.0987, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11316332966089249\n",
            "Loss tensor(0.0970, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11310700327157974\n",
            "Loss tensor(0.0968, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11304992437362671\n",
            "Loss tensor(0.1006, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11300186812877655\n",
            "0.00015734863014170265\n",
            "Loss tensor(0.0962, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1129487156867981\n",
            "Loss tensor(0.1002, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11290301382541656\n",
            "Loss tensor(0.0965, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11285195499658585\n",
            "Loss tensor(0.0990, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11280550062656403\n",
            "0.00014396032034922474\n",
            "Loss tensor(0.0993, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11276349425315857\n",
            "Loss tensor(0.0973, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11271771043539047\n",
            "Loss tensor(0.0977, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11267328262329102\n",
            "Loss tensor(0.0962, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11262615770101547\n",
            "0.00013159078642525112\n",
            "Loss tensor(0.0973, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11258578300476074\n",
            "Loss tensor(0.0952, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11254135519266129\n",
            "Loss tensor(0.0993, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11250323802232742\n",
            "Loss tensor(0.0975, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11246253550052643\n",
            "0.00012017423417831153\n",
            "Loss tensor(0.0952, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11242244392633438\n",
            "Loss tensor(0.0986, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1123872697353363\n",
            "Loss tensor(0.0960, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11234841495752335\n",
            "Loss tensor(0.0985, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11231335997581482\n",
            "0.00010964802388532074\n",
            "Loss tensor(0.0970, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11227956414222717\n",
            "Loss tensor(0.0965, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11224532127380371\n",
            "Loss tensor(0.0963, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11221116036176682\n",
            "Loss tensor(0.0974, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11217745393514633\n",
            "9.995261976784023e-05\n",
            "Loss tensor(0.0963, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11214634776115417\n",
            "Loss tensor(0.0956, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11211445182561874\n",
            "Loss tensor(0.0950, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11208149790763855\n",
            "Loss tensor(0.0995, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11205372959375381\n",
            "9.103152984320604e-05\n",
            "Loss tensor(0.0969, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1120261624455452\n",
            "Loss tensor(0.0955, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11199706047773361\n",
            "Loss tensor(0.0971, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1119694709777832\n",
            "Loss tensor(0.0960, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11194118857383728\n",
            "8.283123734595636e-05\n",
            "Loss tensor(0.0977, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11191681772470474\n",
            "Loss tensor(0.0964, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.1118914932012558\n",
            "Loss tensor(0.0965, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11186616867780685\n",
            "Loss tensor(0.0943, grad_fn=<SumBackward0>)\n",
            "L2 norm of w: 0.11183889955282211\n"
          ]
        }
      ],
      "source": [
        "train(lambd=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxo5kPj6PELP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
